{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import matplotlib.pyplot as plt\n",
    "# from imageai import Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPS:\n",
    "    def __init__(self):\n",
    "        self.pTime = time.time()\n",
    "    def update(self, img=None, pos=(20, 50), color=(255, 0, 0), scale=3, thickness=3):\n",
    "        cTime = time.time()\n",
    "        try:\n",
    "            fps = 1 / (cTime - self.pTime)\n",
    "            self.pTime = cTime\n",
    "            if img is None:\n",
    "                return fps\n",
    "            else:\n",
    "                cv2.putText(img, f\"FPS: {int(fps)}\", pos, cv2.FONT_HERSHEY_PLAIN, scale, color, thickness)\n",
    "                return fps, img\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "_, image = cap.read()\n",
    "HEIGHT, WIDTH, _ = image.shape\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = None\n",
    "with open('./yolo/coco.names', 'rt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configPath = './yolo/yolov3-tiny.cfg'\n",
    "weightsPath = './yolo/yolov3-tiny.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn_DetectionModel(weightsPath, configPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "configPath2 = './yolo/cross-hands-yolov4-tiny.cfg'\n",
    "weightsPath2 = './yolo/cross-hands-yolov4-tiny.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = cv2.dnn_DetectionModel(weightsPath2, configPath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 000001FDD89CB430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.setInputSize(width=WIDTH//3, height=HEIGHT//3)\n",
    "net.setInputScale(1.0 / 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 000001FDD89CB6F0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.setInputSize(width=WIDTH//3, height=HEIGHT//3)\n",
    "net2.setInputScale(1.0 / 127.5)\n",
    "net2.setInputMean((127.5, 127.5, 127.5))\n",
    "net2.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = keras.models.load_model('./tfmodels/best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 512)         590336    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                6425      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,484,505\n",
      "Trainable params: 13,484,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = FPS()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# def main():\n",
    "while True:\n",
    "    try:\n",
    "        _,img = cap.read()\n",
    "        fps.update(img)\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # Detecting objects\n",
    "        classIds, confs, bbox = net.detect(img, confThreshold = 0.5)\n",
    "        handIds, handConfs, handBbox = net2.detect(img, confThreshold = 0.5)\n",
    "        # print(classIds, bbox)\n",
    "\n",
    "        bbox = list(bbox)\n",
    "        confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "        handBbox = list(handBbox)\n",
    "        handConfs = list(np.array(handConfs).reshape(1, -1)[0])\n",
    "        # confs = list(map(float, confs))\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(bbox, confs, 0.5, 0.2)\n",
    "        handindices = cv2.dnn.NMSBoxes(handBbox, handConfs, 0.5, 0.2)\n",
    "        # print(indices)\n",
    "\n",
    "        for i in handindices:\n",
    "            box = handBbox[i]\n",
    "            x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            handimg = img[box[1]:box[1]+box[3], box[0]:box[0]+box[2]]\n",
    "            handimg = cv2.resize(handimg, (28, 28))\n",
    "            handimg_gray = cv2.cvtColor(handimg, cv2.COLOR_BGR2GRAY)\n",
    "            ans = classifier.predict(handimg_gray.reshape(1, 28, 28, 1))\n",
    "            cv2.putText(img, f'hand gesture : {np.argmax(ans, axis=1)}', box[:2], cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            # cv2.imshow('hand', handimg)\n",
    "\n",
    "        for i in indices:\n",
    "            box = bbox[i]\n",
    "            x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(img, f'{classes[classIds[i]].upper()} {confs[i]}', (box[0], box[1]), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "# main()\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import tello\n",
    "from FaceTrackerModule import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n"
     ]
    }
   ],
   "source": [
    "pErrorYV, pErrorUD = 0, 0\n",
    "HEIGHT, WIDTH = 360, 480\n",
    "\n",
    "drone = tello.Tello()\n",
    "keepRecording = True\n",
    "\n",
    "testing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    drone.connect()\n",
    "    drone.streamon()\n",
    "    if drone.get_battery() < 20:\n",
    "        return False\n",
    "\n",
    "    print(drone.get_battery())\n",
    "\n",
    "    if not testing:\n",
    "        drone.takeoff()\n",
    "        drone.move_up(80)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image():\n",
    "    img = drone.get_frame_read().frame\n",
    "    img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    if not init():\n",
    "        return\n",
    "\n",
    "    global pErrorYV, pErrorUD\n",
    "\n",
    "    video1 = cv2.VideoWriter(os.path.join('images', '{}raw.avi'.format(time())), cv2.VideoWriter_fourcc(*'XVID'), 30, (WIDTH, HEIGHT))\n",
    "    video2 = cv2.VideoWriter(os.path.join('images', '{}.avi'.format(time())), cv2.VideoWriter_fourcc(*'XVID'), 30, (WIDTH, HEIGHT))\n",
    "\n",
    "    run = True\n",
    "    while run:\n",
    "\n",
    "        img = get_image()\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        raw = img.copy()\n",
    "\n",
    "        img, face_info, hand_info = processFrame(img)\n",
    "        commands, pErrorYV, pErrorUD = follow_face(face_info, pErrorYV, pErrorUD)\n",
    "        displayText(img, commands, face_info, hand_info)    \n",
    "        cv2.imshow('img', raw)\n",
    "        cv2.imshow('processed', img)\n",
    "        video1.write(raw)\n",
    "        video2.write(img)\n",
    "\n",
    "        lr, fb, ud, yv = commands\n",
    "        if not testing:\n",
    "            drone.send_rc_control(lr, fb, ud, yv)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            run = False\n",
    "\n",
    "        if drone.get_battery() < 20:\n",
    "            run = False\n",
    "\n",
    "    video1.release()\n",
    "    video2.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    if not testing:\n",
    "        drone.land()\n",
    "    drone.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d30c6473a0766cc5fb559e8f04d5daab262e6ba8cc299e27c4b5d4beb8c81fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
